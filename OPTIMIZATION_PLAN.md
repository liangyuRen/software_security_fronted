# ğŸ”§ VulSystem SCA ä¼˜åŒ–æ–¹æ¡ˆ - å®Œæ•´å®æ–½æŒ‡å—

## ğŸ“‹ ç›®å½•
1. [é—®é¢˜æ€»ç»“](#é—®é¢˜æ€»ç»“)
2. [ç¬¬ä¸€é˜¶æ®µï¼šå…³é”®ä¿®å¤](#ç¬¬ä¸€é˜¶æ®µå…³é”®ä¿®å¤)
3. [ç¬¬äºŒé˜¶æ®µï¼šé«˜ä¸¥é‡æ€§ä¿®å¤](#ç¬¬äºŒé˜¶æ®µé«˜ä¸¥é‡æ€§ä¿®å¤)
4. [ç¬¬ä¸‰é˜¶æ®µï¼šæ¶æ„ä¼˜åŒ–](#ç¬¬ä¸‰é˜¶æ®µæ¶æ„ä¼˜åŒ–)
5. [å®æ–½æ—¶é—´è¡¨](#å®æ–½æ—¶é—´è¡¨)

---

## é—®é¢˜æ€»ç»“

### ğŸš¨ å…³é”®é—®é¢˜ï¼ˆç”Ÿäº§çº§é˜»å¡ï¼‰

| # | é—®é¢˜ | å½“å‰çŠ¶æ€ | ä¿®å¤éš¾åº¦ | ä¼˜å…ˆçº§ |
|---|------|--------|--------|--------|
| 1 | **ç‰ˆæœ¬çº¦æŸä¸¢å¤±** | æ‰€æœ‰è§£æå™¨éƒ½åªæ•è·ç¬¬ä¸€ä¸ªç‰ˆæœ¬å· | â­â­ | P0 |
| 2 | **æ— æ•°æ®æŒä¹…åŒ–** | æ¯æ¬¡è§£æéƒ½é‡æ–°åˆ†æ | â­â­â­ | P0 |
| 3 | **Cè¯­è¨€éåŠŸèƒ½** | ä»…æ”¯æŒkulin.txtæ ¼å¼ | â­â­â­â­ | P1 |
| 4 | **Erlangè„†å¼±è§£æ** | æ­£åˆ™å¤ªè„†å¼± | â­â­ | P1 |
| 5 | **LLMå•ç‚¹æ•…éšœ** | LLMå¤±è´¥å¯¼è‡´å…¨éƒ¨å¤±è´¥ | â­â­ | P0 |

### âš ï¸ é«˜ä¸¥é‡æ€§é—®é¢˜ï¼ˆæ¼æ´è¦†ç›–ä¸è¶³ï¼‰

| # | é—®é¢˜ | å½±å“èŒƒå›´ | æ£€æµ‹æ¼æ´ç‡ | ä¿®å¤éš¾åº¦ |
|---|------|--------|----------|--------|
| 6 | ä¼ é€’ä¾èµ–ç¼ºå¤± | Java/Python | æ¼æ‰30-40% | â­â­â­ |
| 7 | TF-IDFç²¾åº¦ä½ | å…¨å±€ | å‡é˜³æ€§40-60% | â­â­â­â­ |
| 8 | Pythonå¤æ‚ä¾èµ– | Pythoné¡¹ç›® | æ¼æ‰extras | â­â­â­ |
| 9 | JavaScriptå·¥ä½œåŒº | Node.jsé¡¹ç›® | æ¼æ‰workspace | â­â­ |
| 10 | Goé—´æ¥ä¾èµ– | Goé¡¹ç›® | æ¼æ‰100% | â­ |

---

## ç¬¬ä¸€é˜¶æ®µï¼šå…³é”®ä¿®å¤

### ä»»åŠ¡ 1.1: ç‰ˆæœ¬çº¦æŸè§£æï¼ˆ10-15å°æ—¶ï¼‰

**ç›®æ ‡:** æ”¯æŒæ‰€æœ‰å¸¸è§çš„ç‰ˆæœ¬çº¦æŸæ ¼å¼ï¼Œä¸å†ä¸¢å¼ƒç‰ˆæœ¬ä¿¡æ¯

**éœ€è¦ä¿®æ”¹çš„æ–‡ä»¶:**
- `flask-crawler/parase/python_parse.py`
- `flask-crawler/parase/pom_parse.py`
- `flask-crawler/parase/javascript_parse.py`
- `flask-crawler/parase/go_parse.py`
- `flask-crawler/parase/php_parse.py`
- `flask-crawler/parase/ruby_parse.py`
- `flask-crawler/parase/rust_parse.py`

**æ”¹è¿›æ–¹æ³•:**

åˆ›å»ºä¸€ä¸ªé€šç”¨çš„ç‰ˆæœ¬çº¦æŸè§£æå™¨ï¼ˆæ‰€æœ‰è¯­è¨€å¤ç”¨ï¼‰ï¼š

```python
# flask-crawler/parase/version_parser.py (æ–°æ–‡ä»¶)

import re
from typing import List, Tuple, Dict

class VersionConstraint:
    """è¡¨ç¤ºç‰ˆæœ¬çº¦æŸ"""
    def __init__(self, operator: str, version: str):
        self.operator = operator  # ==, >=, >, <=, <, ~=, ^, etc.
        self.version = version

    def __repr__(self):
        return f"{self.operator}{self.version}"

def parse_version_constraints(constraint_str: str) -> List[VersionConstraint]:
    """
    è§£æç‰ˆæœ¬çº¦æŸå­—ç¬¦ä¸²

    æ”¯æŒæ ¼å¼:
    - å•çº¦æŸ: >=1.0.0, ~=2.0, ^3.0.1
    - èŒƒå›´: >=1.0.0,<2.0.0
    - MavenèŒƒå›´: [1.0,2.0), (1.0,2.0]
    - NPMèŒƒå›´: 1.x, 1.2.x, ~1.2.3

    è¿”å›: List[VersionConstraint]
    """
    constraints = []

    if not constraint_str or constraint_str.strip() == '':
        return constraints

    constraint_str = constraint_str.strip()

    # Mavenæ ¼å¼: [1.0,2.0) æˆ– (1.0,2.0]
    maven_pattern = r'[\[\(](.*?)[,\s](.*?)[\]\)]'
    maven_match = re.match(maven_pattern, constraint_str)
    if maven_match:
        lower, upper = maven_match.groups()
        if constraint_str.startswith('['):
            constraints.append(VersionConstraint('>=', lower.strip()))
        else:
            constraints.append(VersionConstraint('>', lower.strip()))

        if constraint_str.endswith(']'):
            constraints.append(VersionConstraint('<=', upper.strip()))
        else:
            constraints.append(VersionConstraint('<', upper.strip()))
        return constraints

    # å¤šä¸ªçº¦æŸç”¨é€—å·åˆ†éš”: >=1.0.0,<2.0.0
    parts = constraint_str.split(',')

    for part in parts:
        part = part.strip()
        if not part:
            continue

        # åŒ¹é…æ“ä½œç¬¦å’Œç‰ˆæœ¬å·
        # æ”¯æŒ: >=1.0.0, ~=1.2.0, ^1.0.0, 1.0.0 (é»˜è®¤==)
        match = re.match(r'^([=~><!^]+)?(.+)$', part)
        if match:
            op, version = match.groups()
            op = op or '=='  # é»˜è®¤ç›¸ç­‰

            # ç‰¹æ®Šå¤„ç†NPMçš„~å’Œ^
            if op in ['~', '^']:
                constraints.append(VersionConstraint(op, version.strip()))
            else:
                # æ ‡å‡†åŒ–æ“ä½œç¬¦
                constraints.append(VersionConstraint(op, version.strip()))

    return constraints if constraints else [VersionConstraint('==', constraint_str)]
```

**åœ¨Pythonè§£æå™¨ä¸­ä½¿ç”¨:**

```python
# ä¿®æ”¹ python_parse.py çš„ parse_requirements_txt å‡½æ•°
from parase.version_parser import parse_version_constraints

def parse_requirements_txt(requirements_path):
    dependencies = []
    with open(requirements_path, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if not line or line.startswith('#'):
                continue

            # å¤„ç†extras: requests[security]>=2.28.0
            extras = []
            pkg_with_extras = line.split('[')
            pkg_part = pkg_with_extras[0]

            if len(pkg_with_extras) > 1:
                extras_str = pkg_with_extras[1].split(']')[0]
                extras = [e.strip() for e in extras_str.split(',')]

            # åˆ†ç¦»åŒ…åå’Œç‰ˆæœ¬çº¦æŸ
            match = re.match(r'^([a-zA-Z0-9_\-]+)\s*(.*?)$', pkg_part)
            if match:
                pkg_name, constraint = match.groups()
                constraint = constraint.strip()

                # è§£æç‰ˆæœ¬çº¦æŸ
                version_constraints = parse_version_constraints(constraint)

                # æ„å»ºä¾èµ–å¯¹è±¡
                dep = {
                    'name': pkg_name,
                    'constraints': [str(c) for c in version_constraints],
                    'extras': extras,
                    'constraint_string': constraint or '(unspecified)'
                }
                dependencies.append(dep)

    return dependencies
```

**æ•°æ®åº“å­˜å‚¨æ ¼å¼:**

```sql
-- ä¿®æ”¹ white_list è¡¨ç»“æ„ï¼ˆåç«¯ï¼‰
ALTER TABLE white_list ADD COLUMN version_constraint VARCHAR(255);
ALTER TABLE white_list ADD COLUMN min_version VARCHAR(50);
ALTER TABLE white_list ADD COLUMN max_version VARCHAR(50);
ALTER TABLE white_list ADD COLUMN constraint_type VARCHAR(50);
-- ç¤ºä¾‹: constraint_type: 'exact', 'range', 'minimum', 'compatible'
```

**è¿”å›æ ¼å¼ï¼ˆFlaskï¼‰:**

```json
{
  "dependencies": [
    {
      "name": "requests",
      "version": "2.31.0",
      "constraints": [">=2.28.0", "<3.0.0"],
      "type": "production"
    },
    {
      "name": "pytest",
      "version": "7.4.0",
      "constraints": [">=7.0"],
      "type": "development"
    }
  ],
  "metadata": {
    "total": 15,
    "with_constraints": 12,
    "without_constraints": 3
  }
}
```

---

### ä»»åŠ¡ 1.2: æ•°æ®æŒä¹…åŒ– (15-20å°æ—¶)

**ç›®æ ‡:** é¿å…é‡å¤è§£æï¼Œå­˜å‚¨å·²è§£æçš„ä¾èµ–åˆ°æ•°æ®åº“

**å®ç°æ­¥éª¤:**

1. **åˆ›å»ºä¾èµ–ç¼“å­˜è¡¨** (åç«¯ Spring Boot):

```sql
CREATE TABLE project_dependency_cache (
  id BIGINT PRIMARY KEY AUTO_INCREMENT,
  project_id BIGINT NOT NULL,
  upload_file_hash VARCHAR(64) NOT NULL,
  parsed_dependencies JSON NOT NULL,
  parse_timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,
  expires_at DATETIME,
  UNIQUE KEY uk_project_hash (project_id, upload_file_hash),
  FOREIGN KEY (project_id) REFERENCES project(id)
);

-- ç´¢å¼•ç”¨äºå¿«é€ŸæŸ¥è¯¢
CREATE INDEX idx_project_expires ON project_dependency_cache(project_id, expires_at);
```

2. **ä¿®æ”¹åç«¯ ProjectService**:

```java
// backend/src/main/java/com/nju/backend/service/project/ProjectService.java

@Service
public class ProjectService {

    @Autowired
    private ProjectDependencyCacheMapper cacheMapper;

    @Autowired
    private RestTemplate restTemplate;  // è°ƒç”¨Flask

    public List<ProjectDependency> parseDependencies(Project project, File uploadedFile) {
        // 1. è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
        String fileHash = calculateSHA256(uploadedFile);

        // 2. æŸ¥è¯¢ç¼“å­˜
        ProjectDependencyCache cached = cacheMapper.selectByProjectAndHash(
            project.getId(), fileHash
        );

        if (cached != null && !isExpired(cached)) {
            logger.info("ä½¿ç”¨ç¼“å­˜çš„ä¾èµ–è§£æç»“æœ: project_id={}", project.getId());
            return parseJsonDependencies(cached.getParsedDependencies());
        }

        // 3. è°ƒç”¨Flaskçˆ¬è™«è§£æ
        List<ProjectDependency> dependencies = callFlaskParser(uploadedFile, project);

        // 4. ä¿å­˜åˆ°ç¼“å­˜
        ProjectDependencyCache cache = new ProjectDependencyCache();
        cache.setProjectId(project.getId());
        cache.setUploadFileHash(fileHash);
        cache.setParsedDependencies(toJsonString(dependencies));
        cache.setExpiresAt(calculateExpiryTime());  // 30å¤©è¿‡æœŸ
        cacheMapper.insert(cache);

        return dependencies;
    }

    private String calculateSHA256(File file) throws IOException {
        MessageDigest digest = MessageDigest.getInstance("SHA-256");
        byte[] fileBytes = Files.readAllBytes(file.toPath());
        byte[] hashBytes = digest.digest(fileBytes);
        return bytesToHex(hashBytes);
    }
}
```

3. **ä¿®æ”¹Flaskçˆ¬è™«**:

```python
# flask-crawler/app.py æ·»åŠ ç¼“å­˜å±‚

from functools import lru_cache
import hashlib

PARSE_CACHE = {}  # ç®€å•å†…å­˜ç¼“å­˜ï¼Œå¯å‡çº§ä¸ºRedis

@app.route('/parse/python_parse', methods=['GET'])
def python_parse_api():
    file_path = request.args.get('file_path')

    # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
    file_hash = hashlib.sha256(open(file_path, 'rb').read()).hexdigest()

    # æ£€æŸ¥ç¼“å­˜
    if file_hash in PARSE_CACHE:
        logger.info(f"Flaskç¼“å­˜å‘½ä¸­: {file_hash}")
        return jsonify(PARSE_CACHE[file_hash])

    # æ‰§è¡Œè§£æ
    try:
        dependencies = parse_python_project(file_path)
        result = {
            'status': 'success',
            'dependencies': dependencies,
            'timestamp': datetime.now().isoformat()
        }

        # ä¿å­˜åˆ°ç¼“å­˜ (1å°æ—¶è¿‡æœŸ)
        PARSE_CACHE[file_hash] = result

        return jsonify(result)
    except Exception as e:
        return jsonify({'status': 'error', 'message': str(e)}), 400
```

---

### ä»»åŠ¡ 1.3: é”™è¯¯å¤„ç†å’ŒéªŒè¯ (10-15å°æ—¶)

**ç›®æ ‡:** ä¸å†æ— å£°åœ°å¤±è´¥ï¼Œæä¾›è¯¦ç»†çš„é”™è¯¯ä¿¡æ¯å’Œæ—¥å¿—

**å®ç°:**

```python
# flask-crawler/parase/base_parser.py (æ–°æ–‡ä»¶ - æ‰€æœ‰è§£æå™¨çš„åŸºç±»)

import logging
from typing import List, Dict, Optional
from dataclasses import dataclass
from enum import Enum

logger = logging.getLogger(__name__)

class ParseErrorLevel(Enum):
    ERROR = "error"        # è‡´å‘½é”™è¯¯ï¼Œæ— æ³•ç»§ç»­
    WARNING = "warning"    # è­¦å‘Šï¼Œéƒ¨åˆ†è§£ææˆåŠŸ
    INFO = "info"          # ä¿¡æ¯æ€§æ¶ˆæ¯

@dataclass
class ParseError:
    level: ParseErrorLevel
    file: str
    message: str
    line_number: Optional[int] = None

    def __str__(self):
        if self.line_number:
            return f"[{self.level.value}] {self.file}:{self.line_number} - {self.message}"
        return f"[{self.level.value}] {self.file} - {self.message}"

class BaseParser:
    def __init__(self, project_path: str):
        self.project_path = project_path
        self.errors: List[ParseError] = []
        self.logger = logging.getLogger(self.__class__.__name__)

    def parse(self) -> Dict:
        """æ‰§è¡Œè§£æå¹¶è¿”å›ç»“æœ"""
        try:
            result = self._parse_impl()
            return {
                'status': 'success',
                'dependencies': result.get('dependencies', []),
                'warnings': [e.message for e in self.errors
                            if e.level == ParseErrorLevel.WARNING],
                'errors': [e.message for e in self.errors
                          if e.level == ParseErrorLevel.ERROR]
            }
        except Exception as e:
            self.logger.error(f"è§£æå¤±è´¥: {e}", exc_info=True)
            return {
                'status': 'error',
                'dependencies': [],
                'errors': [str(e)]
            }

    def add_error(self, level: ParseErrorLevel, file: str, message: str, line: int = None):
        """è®°å½•è§£æé”™è¯¯"""
        error = ParseError(level, file, message, line)
        self.errors.append(error)
        self.logger.log(
            logging.WARNING if level == ParseErrorLevel.WARNING else logging.ERROR,
            str(error)
        )

    def _parse_impl(self) -> Dict:
        """å­ç±»å®ç°çš„å…·ä½“è§£æé€»è¾‘"""
        raise NotImplementedError

# ä½¿ç”¨ç¤ºä¾‹
class PythonParser(BaseParser):
    def _parse_impl(self) -> Dict:
        dependencies = []

        # å°è¯•è§£ærequirements.txt
        req_file = os.path.join(self.project_path, 'requirements.txt')
        if os.path.exists(req_file):
            try:
                deps = self._parse_requirements(req_file)
                dependencies.extend(deps)
            except FileNotFoundError:
                self.add_error(
                    ParseErrorLevel.WARNING,
                    'requirements.txt',
                    f"æ–‡ä»¶ä¸å­˜åœ¨æˆ–æ— æ³•è¯»å–"
                )
            except Exception as e:
                self.add_error(
                    ParseErrorLevel.WARNING,
                    'requirements.txt',
                    f"è§£æå¤±è´¥: {str(e)}"
                )
        else:
            self.add_error(
                ParseErrorLevel.WARNING,
                'requirements.txt',
                "æœªæ‰¾åˆ°ä¾èµ–æ–‡ä»¶"
            )

        return {'dependencies': dependencies}
```

---

### ä»»åŠ¡ 1.4: ç§»é™¤LLMä¾èµ– (8-12å°æ—¶)

**é—®é¢˜:** å½“å‰æ‰€æœ‰è§£æå™¨éƒ½ä¾èµ–LLMç”Ÿæˆç»„ä»¶æè¿°ï¼Œå¯¼è‡´å•ç‚¹æ•…éšœ

**è§£å†³æ–¹æ¡ˆ:** å°†LLMæ”¹ä¸ºå¯é€‰çš„å¢å¼ºè€Œä¸æ˜¯å¿…éœ€æ­¥éª¤

```python
# flask-crawler/parase/pom_parse.py ä¿®æ”¹

def parse_pom(pom_path: str, use_llm: bool = False) -> Dict:
    """
    è§£æPOMæ–‡ä»¶

    Args:
        pom_path: POMæ–‡ä»¶è·¯å¾„
        use_llm: æ˜¯å¦ä½¿ç”¨LLMç”Ÿæˆæè¿° (å¯é€‰)

    Returns:
        è§£æç»“æœçš„å­—å…¸
    """
    dependencies = []

    try:
        tree = ET.parse(pom_path)
        root = tree.getroot()

        # è§£æä¾èµ– - è¿™éƒ¨åˆ†ä¸éœ€è¦LLM
        for dep in root.findall('.//dependency', namespaces):
            group_id = get_element_text(dep, 'groupId', namespaces)
            artifact_id = get_element_text(dep, 'artifactId', namespaces)
            version = get_element_text(dep, 'version', namespaces)
            scope = get_element_text(dep, 'scope', namespaces) or 'compile'

            # åŸºç¡€ä¿¡æ¯å®Œæ•´ï¼Œä¸éœ€è¦LLM
            dependencies.append({
                'name': f"{group_id}:{artifact_id}",
                'version': version,
                'scope': scope
            })

    except Exception as e:
        logger.error(f"POMè§£æå¤±è´¥: {e}")
        return {'status': 'error', 'dependencies': []}

    # ä»…å½“æ˜ç¡®è¦æ±‚æ—¶æ‰è°ƒç”¨LLMå¢å¼ºï¼ˆå¼‚æ­¥ï¼Œä¸é˜»å¡ï¼‰
    if use_llm and dependencies:
        try:
            enhanced = enhance_with_llm(dependencies)
            return {
                'status': 'success',
                'dependencies': enhanced,
                'enhanced': True
            }
        except Exception as e:
            logger.warning(f"LLMå¢å¼ºå¤±è´¥ï¼Œè¿”å›åŸºç¡€ä¿¡æ¯: {e}")
            return {
                'status': 'success',
                'dependencies': dependencies,
                'enhanced': False
            }

    return {
        'status': 'success',
        'dependencies': dependencies,
        'enhanced': False
    }
```

---

## ç¬¬äºŒé˜¶æ®µï¼šé«˜ä¸¥é‡æ€§ä¿®å¤

### ä»»åŠ¡ 2.1: ä¼ é€’ä¾èµ–è§£æ (20-30å°æ—¶)

**å½“å‰é—®é¢˜:**
- Java: å¿½ç•¥parent POMï¼Œæ— æ³•è·å–ç»§æ‰¿çš„ä¾èµ–
- Python: ä»…è§£æç›´æ¥ä¾èµ–ï¼Œå¿½ç•¥lockæ–‡ä»¶çš„æ ‘
- JavaScript: ä»…æ‰«ææ ¹ç›®å½•package.json

**è§£å†³æ–¹æ¡ˆ:**

å¯¹äºJavaï¼Œä½¿ç”¨Mavenä¾èµ–æ ‘ï¼š

```python
# flask-crawler/parase/pom_parse.py æ–°å¢

import subprocess
import json

def get_maven_dependency_tree(project_path: str) -> Dict:
    """
    è°ƒç”¨Mavenè·å–å®Œæ•´çš„ä¾èµ–æ ‘ï¼ˆåŒ…æ‹¬ä¼ é€’ä¾èµ–ï¼‰

    è¦æ±‚ï¼šé¡¹ç›®æ ¹ç›®å½•æœ‰pom.xml
    """
    try:
        # ä½¿ç”¨maven-dependency-pluginç”ŸæˆJSONæ ¼å¼çš„ä¾èµ–æ ‘
        result = subprocess.run(
            ['mvn', 'dependency:tree', '-DoutputFile=dependency-tree.json',
             '-Doutput=com.fasterxml.jackson.databind.ObjectMapper'],
            cwd=project_path,
            capture_output=True,
            text=True,
            timeout=120
        )

        if result.returncode == 0:
            with open(os.path.join(project_path, 'dependency-tree.json')) as f:
                return json.load(f)
    except subprocess.TimeoutExpired:
        logger.warning("Mavenä¾èµ–æ ‘ç”Ÿæˆè¶…æ—¶")
    except Exception as e:
        logger.warning(f"è·å–Mavenä¾èµ–æ ‘å¤±è´¥: {e}")

    return None

def parse_pom_with_transitive(pom_path: str) -> List[Dict]:
    """è§£æPOMå¹¶åŒ…å«ä¼ é€’ä¾èµ–"""
    project_path = os.path.dirname(pom_path)
    all_dependencies = []

    # é¦–å…ˆå°è¯•ä½¿ç”¨Mavenè·å–å®Œæ•´ä¾èµ–æ ‘
    maven_tree = get_maven_dependency_tree(project_path)
    if maven_tree:
        return parse_maven_tree(maven_tree)

    # å¤‡é€‰æ–¹æ¡ˆï¼šæ‰‹åŠ¨è§£æï¼ˆå¯¹æ¯”ä¹‹å‰çš„ç›´æ¥ä¾èµ–è§£æï¼‰
    direct_deps = parse_pom_direct(pom_path)

    # å¯¹äºæ¯ä¸ªä¾èµ–ï¼Œå°è¯•æŸ¥æ‰¾å…¶è‡ªå·±çš„POMå¹¶é€’å½’è§£æ
    resolved_deps = resolve_transitive_deps(direct_deps, project_path)

    return resolved_deps
```

---

### ä»»åŠ¡ 2.2: æ”¹è¿›TF-IDFåŒ¹é… (25-35å°æ—¶)

**å½“å‰é—®é¢˜:**
- ä½¿ç”¨é€šç”¨æ–‡æœ¬TF-IDFï¼Œä¸é€‚åˆåŒ…ååŒ¹é…
- æ²¡æœ‰å‘½åå®ä½“è¯†åˆ«ï¼ˆæ— æ³•ä»CVEæè¿°æå–åŒ…åï¼‰
- å‡é˜³æ€§ç‡40-60%

**è§£å†³æ–¹æ¡ˆ:**

```python
# flask-crawler/VulLibGen/tf_idf/enhanced_matching.py (æ–°æ–‡ä»¶)

import re
from typing import List, Tuple, Dict
import numpy as np

class VulnerabilityMatcher:
    """æ”¹è¿›çš„æ¼æ´-ç»„ä»¶åŒ¹é…å™¨"""

    def __init__(self):
        # å¸¸è§çš„åŒ…åå‰ç¼€/åç¼€æ¨¡å¼
        self.package_patterns = {
            'java': [
                r'([a-z0-9]+(?:\.[a-z0-9]+)*:[a-z0-9\-]+)',  # groupId:artifactId
                r'(org\.[a-z]+\.[\w\-\.]+)',
            ],
            'python': [
                r'\b([a-z0-9\-_]+)\b',  # ç®€å•åŒ…å
                r'from\s+([a-z0-9_\.]+)',  # importå¯¼å…¥
            ],
            'javascript': [
                r'(@[a-z0-9\-]+/)?([a-z0-9\-]+)',  # scopedæˆ–ç®€å•åŒ…å
                r'require\(["\']([^"\']+)["\']',
            ],
        }

        # åŸŸç‰¹å®šå…³é”®å­—æƒé‡ï¼ˆåŠ å¼ºå¯¹åŒ…åçš„åŒ¹é…ï¼‰
        self.domain_keywords = {
            'log4j': ['logging', 'logger', 'appender', 'slf4j'],
            'spring': ['spring', 'framework', 'mvc', 'boot', 'bean'],
            'django': ['django', 'web', 'framework', 'orm', 'template'],
            'requests': ['http', 'request', 'urllib', 'api', 'client'],
            'openssl': ['ssl', 'tls', 'encryption', 'crypto', 'certificate'],
        }

    def extract_package_names_from_cve(self, cve_description: str, language: str) -> List[str]:
        """
        ä»CVEæè¿°ä¸­æå–å¯èƒ½çš„åŒ…å

        ä½¿ç”¨æ¨¡å¼åŒ¹é… + å¯å‘å¼æ–¹æ³•
        """
        extracted = set()
        patterns = self.package_patterns.get(language, [])

        for pattern in patterns:
            matches = re.findall(pattern, cve_description, re.IGNORECASE)
            extracted.update(matches)

        # æ¸…ç†å’Œè¿‡æ»¤ç»“æœ
        cleaned = set()
        for name in extracted:
            if isinstance(name, tuple):
                name = ''.join(filter(None, name))  # å¤„ç†æ•è·ç»„

            # è¿‡æ»¤æ‰å¸¸è§çš„å‡é˜³æ€§
            if len(name) > 2 and not self._is_stopword(name):
                cleaned.add(name.lower())

        return list(cleaned)

    def calculate_similarity(self, pkg_name: str, cve_desc: str, language: str) -> float:
        """
        è®¡ç®—åŒ…å’ŒCVEçš„ç›¸ä¼¼åº¦

        ä½¿ç”¨å¤šä¸ªä¿¡å·çš„ç»„åˆï¼š
        1. åå­—çš„ç²¾ç¡®/éƒ¨åˆ†åŒ¹é…
        2. åŸŸç‰¹å®šå…³é”®å­—åŒ¹é…
        3. ç‰ˆæœ¬å·ç›¸å…³æ€§
        """
        similarity_scores = []

        # ä¿¡å·1ï¼šç²¾ç¡®åå­—åŒ¹é…ï¼ˆæƒé‡æœ€é«˜ï¼‰
        if pkg_name.lower() in cve_desc.lower():
            similarity_scores.append(('exact_match', 1.0))

        # ä¿¡å·2ï¼šéƒ¨åˆ†åå­—åŒ¹é…
        pkg_parts = re.split(r'[:\-/_]', pkg_name.lower())
        matched_parts = sum(1 for part in pkg_parts
                          if len(part) > 2 and part in cve_desc.lower())
        partial_score = matched_parts / len(pkg_parts) if pkg_parts else 0
        similarity_scores.append(('partial_match', partial_score * 0.7))

        # ä¿¡å·3ï¼šåŸŸç‰¹å®šå…³é”®å­—
        keyword_score = self._calculate_keyword_score(pkg_name, cve_desc)
        similarity_scores.append(('domain_keywords', keyword_score * 0.5))

        # ä¿¡å·4ï¼šç›¸å…³åŒ…åï¼ˆå¦‚log4jå’Œslf4jï¼‰
        related_score = self._calculate_related_package_score(pkg_name, cve_desc)
        similarity_scores.append(('related_packages', related_score * 0.3))

        # åŠ æƒå¹³å‡
        total_score = sum(score for _, score in similarity_scores)
        max_score = sum(weight for _, weight in similarity_scores)

        final_score = total_score / max_score if max_score > 0 else 0

        return min(final_score, 1.0)  # ç¡®ä¿åœ¨0-1ä¹‹é—´

    def _is_stopword(self, word: str) -> bool:
        """æ£€æŸ¥æ˜¯å¦æ˜¯åœç”¨è¯"""
        stopwords = {
            'the', 'and', 'or', 'a', 'an', 'in', 'on', 'at', 'to', 'for',
            'of', 'is', 'are', 'was', 'were', 'be', 'have', 'has', 'had',
            'do', 'does', 'did', 'will', 'would', 'could', 'should',
            'may', 'might', 'must', 'can'
        }
        return word.lower() in stopwords or len(word) < 3

    def _calculate_keyword_score(self, pkg_name: str, cve_desc: str) -> float:
        """è®¡ç®—åŸŸç‰¹å®šå…³é”®å­—çš„åŒ¹é…åˆ†æ•°"""
        pkg_base = pkg_name.split(':')[-1].split('/')[-1].lower()  # å–æœ€åçš„ç»„ä»¶å

        keywords = self.domain_keywords.get(pkg_base, [])
        if not keywords:
            return 0

        desc_lower = cve_desc.lower()
        matched = sum(1 for kw in keywords if kw in desc_lower)

        return matched / len(keywords) if keywords else 0

    def _calculate_related_package_score(self, pkg_name: str, cve_desc: str) -> float:
        """è®¡ç®—ç›¸å…³åŒ…åçš„åŒ¹é…åˆ†æ•°"""
        # åŒ…åä¹‹é—´çš„å·²çŸ¥å…³ç³»æ˜ å°„
        package_relations = {
            'log4j': ['log4j2', 'slf4j', 'logback'],
            'openssl': ['ssl', 'tls', 'boringssl', 'libressl'],
            'spring': ['spring-boot', 'spring-cloud', 'spring-security'],
        }

        related_pkgs = []
        for base, related in package_relations.items():
            if base in pkg_name.lower():
                related_pkgs.extend(related)
                break

        if not related_pkgs:
            return 0

        desc_lower = cve_desc.lower()
        matched = sum(1 for pkg in related_pkgs if pkg in desc_lower)

        return matched / len(related_pkgs)

    def match_vulnerabilities(self, components: List[Dict], vulnerabilities: List[Dict]) -> List[Dict]:
        """
        åŒ¹é…æ¼æ´åˆ°ç»„ä»¶

        è¿”å›åŒ¹é…ç»“æœåˆ—è¡¨ï¼ŒåŒ…å«åŒ¹é…åˆ†æ•°
        """
        matches = []

        for comp in components:
            comp_name = comp.get('name')
            comp_version = comp.get('version')
            language = comp.get('language', 'unknown')

            for vuln in vulnerabilities:
                vuln_desc = vuln.get('description', '')
                vuln_title = vuln.get('title', '')

                # è®¡ç®—ç›¸ä¼¼åº¦
                similarity = self.calculate_similarity(comp_name,
                                                      f"{vuln_title} {vuln_desc}",
                                                      language)

                # é˜ˆå€¼è¿‡æ»¤ï¼šåªè¿”å›é«˜äº0.4çš„åŒ¹é…
                if similarity > 0.4:
                    matches.append({
                        'component': comp_name,
                        'vulnerability': vuln.get('id'),
                        'similarity_score': similarity,
                        'confidence': 'high' if similarity > 0.7 else 'medium',
                        'reasoning': f"åå­—åŒ¹é…åˆ†æ•°: {similarity:.2%}"
                    })

        return sorted(matches, key=lambda x: x['similarity_score'], reverse=True)
```

---

## ç¬¬ä¸‰é˜¶æ®µï¼šæ¶æ„ä¼˜åŒ–

### ä»»åŠ¡ 3.1: åˆ†ç¦»è§£æå’ŒåŒ¹é… (20-30å°æ—¶)

**å½“å‰é—®é¢˜:** è§£æå’ŒåŒ¹é…æ··åœ¨ä¸€èµ·ï¼Œä»£ç å¤æ‚ä¸”éš¾ä»¥ç»´æŠ¤

**æ”¹è¿›æ–¹æ¡ˆ:**

```
æ–°æ¶æ„:
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Upload Project (ZIP/TAR)          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Extract Files â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Detect Language & Structure    â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Language-Specific Parser                â”‚
        â”‚  (Python/Java/Go/etc.)                   â”‚
        â”‚  â†’ Extract Dependencies                  â”‚
        â”‚  â†’ Store to ComponentCache               â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Match Against Vulnerability DBâ”‚  (ç‹¬ç«‹çš„åŒ¹é…å¼•æ“)
        â”‚  (TF-IDF / LLM / Exact)        â”‚
        â”‚  â†’ Find Vulnerabilities        â”‚
        â”‚  â†’ Generate Risk Report        â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚  Return Results                â”‚
        â”‚  (Vulnerabilities + Remediation) â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## å®æ–½æ—¶é—´è¡¨

### Week 1: ç¬¬ä¸€é˜¶æ®µï¼ˆå…³é”®ä¿®å¤ï¼‰
- **Day 1-2:** ç‰ˆæœ¬çº¦æŸè§£æï¼ˆæ‰€æœ‰è¯­è¨€ï¼‰
- **Day 3:** æ•°æ®æŒä¹…åŒ–å’Œç¼“å­˜å±‚
- **Day 4:** é”™è¯¯å¤„ç†å’ŒéªŒè¯æ¡†æ¶
- **Day 5:** ç§»é™¤LLMä¾èµ–ï¼Œå®Œæˆç¬¬ä¸€è½®æµ‹è¯•

### Week 2-3: ç¬¬äºŒé˜¶æ®µï¼ˆé«˜ä¸¥é‡æ€§ä¿®å¤ï¼‰
- **Day 6-8:** ä¼ é€’ä¾èµ–è§£æ
- **Day 9-12:** æ”¹è¿›TF-IDFåŒ¹é…
- **Day 13:** è¯­è¨€ç‰¹å®šä¿®å¤å’Œé›†æˆæµ‹è¯•

### Week 4-5: ç¬¬ä¸‰é˜¶æ®µï¼ˆæ¶æ„ä¼˜åŒ–ï¼‰
- **Day 14-17:** åˆ†ç¦»è§£æå’ŒåŒ¹é…
- **Day 18-19:** ç‰ˆæœ¬ç®¡ç†å’Œæ ‡å‡†åŒ–
- **Day 20:** é‡æ„ç¼“å­˜å’Œæ€§èƒ½ä¼˜åŒ–

### Week 6+: ç¬¬å››é˜¶æ®µï¼ˆæµ‹è¯•å’Œéƒ¨ç½²ï¼‰
- **Day 21+:** å•å…ƒæµ‹è¯•ã€é›†æˆæµ‹è¯•ã€æ–‡æ¡£

---

## å…³é”®æŒ‡æ ‡

### å½“å‰çŠ¶æ€
- ä¾èµ–æ£€æµ‹ç‡: 40-70%
- å‡é˜³æ€§ç‡: 40-60%
- è§£æè€—æ—¶: 5-30ç§’/é¡¹ç›®

### ä¼˜åŒ–åç›®æ ‡
- ä¾èµ–æ£€æµ‹ç‡: 85-95%  âœ“
- å‡é˜³æ€§ç‡: < 10%      âœ“
- è§£æè€—æ—¶: 1-5ç§’/é¡¹ç›® (ç¼“å­˜å‘½ä¸­)  âœ“
- ç‰ˆæœ¬çº¦æŸä¿ç•™ç‡: 100%  âœ“
- ä¼ é€’ä¾èµ–è¦†ç›–ç‡: 90%+  âœ“

---

## é£é™©å’Œç¼“è§£

| é£é™© | æ¦‚ç‡ | å½±å“ | ç¼“è§£æ–¹æ¡ˆ |
|------|------|------|--------|
| Mavenä¾èµ–æ ‘ç”Ÿæˆæ…¢ | é«˜ | é¦–æ¬¡è§£æå»¶è¿Ÿ | å¼‚æ­¥+ç¼“å­˜ |
| LLMç§»é™¤å¯¼è‡´ç²¾åº¦ä¸‹é™ | ä½ | è¯¯æ£€å¢åŠ  | æ”¹è¿›TF-IDFä»£å¿ |
| æ•°æ®åº“è¿ç§» | ä¸­ | åœæœºæ—¶é—´ | ç°åº¦éƒ¨ç½² |
| ç‰ˆæœ¬çº¦æŸè§£æå¤æ‚ | ä½ | è¾¹ç•Œæƒ…å†µ | æ‰©å±•å•å…ƒæµ‹è¯• |

